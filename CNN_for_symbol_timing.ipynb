{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_for_symbol_timing.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/planewave/coherent_receiver_with_CNN/blob/master/CNN_for_symbol_timing.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "FMBKD1RXPJfB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "dependency is lost. will need `sig_gen5_new_timing.m` to generate `sto10dB.mat`\n"
      ]
    },
    {
      "metadata": {
        "id": "a20AnSZUSp_6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "accelerator = 'cu90' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5rdHWC49iyvI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf test_repo\n",
        "!git clone https://github.com/planewave/test_repo.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NZhZSfdpjNgb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "USE_CUDA = True\n",
        "NUM_EPO = 50\n",
        "\n",
        "dataRead = io.loadmat('test_repo/sto10dB.mat')\n",
        "\n",
        "offset = dataRead['offset'] #(1024, 1) int64 \n",
        "sig = (dataRead['x']) #(1024, 1, 16, 64)\n",
        "\n",
        "offset = Variable(torch.from_numpy(offset+8).squeeze())\n",
        "sig = Variable(torch.from_numpy(sig)) # floatTensor\n",
        "offset.cuda().shape\n",
        "# type(offset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DErSJXL_keLF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.sto_cnn = nn.Sequential(\n",
        "            nn.Conv2d( 1, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16,  4, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d( 4,  1, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0)),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "    def forward(self, sig):\n",
        "        out_cnn = self.sto_cnn(sig)\n",
        "        out_mean = out_cnn.squeeze().mean(2)\n",
        "        return nn.functional.softmax(out_mean, dim=1)\n",
        "    \n",
        "net = Net()\n",
        "if USE_CUDA:\n",
        "    offset = offset.cuda()\n",
        "    sig = sig.cuda()\n",
        "    net.cuda() # put it before optimizer\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v3CmtWmjpzWL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "DoQHvufjprCj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(NUM_EPO):\n",
        "    netout = net(sig)\n",
        "    target = offset\n",
        "    loss = loss_func(netout, target)\n",
        "    optimizer.zero_grad()                           # clear gradients for this training step\n",
        "    loss.backward()                                 # backpropagation, compute gradients\n",
        "    optimizer.step()\n",
        "    if epoch%5 == 0:\n",
        "        prediction = torch.max(F.softmax(netout, 1), 1)[1]\n",
        "        accu = torch.sum(prediction.data == target.data)/prediction.shape[0]\n",
        "        print('Epoch:', epoch, 'loss:', loss, 'accu', accu)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6wDgXaBHS5ff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b0e88864-2316-42aa-95c5-83ab26606755"
      },
      "cell_type": "code",
      "source": [
        "sig = (dataRead['x'])\n",
        "sig = Variable(torch.from_numpy(sig))\n",
        "m = nn.Sequential(\n",
        "            nn.Conv2d( 1, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16,  4, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d( 4,  1, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0)),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "output = m(sig)\n",
        "output = output.squeeze().mean(2)\n",
        "output.shape\n",
        "\n",
        "# m2 = nn.Softmax(dim=1)\n",
        "# output = m2(output)\n",
        "# output[0,:]\n",
        "# out_cnn = self.sto_cnn(sig)\n",
        "# out_mean = out_cnn.squeeze().mean(2)\n",
        "netout = nn.functional.softmax(output, dim=1)\n",
        "prediction = torch.max(F.softmax(netout, 1), 1)[1]\n",
        "offset = dataRead['offset']\n",
        "target = Variable(torch.from_numpy(offset).squeeze())\n",
        "accu = torch.sum(prediction.data == target.data)/prediction.shape[0]\n",
        "accu\n",
        "\n",
        "# print(target)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "loss = loss_func(netout, target)\n",
        "loss"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Variable containing:\n",
              " 2.7727\n",
              "[torch.FloatTensor of size 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}